---
title: "Section 5.1 Problems"
author: "Ryan Heslin"
Date: "`r format(Sys.Date(), '%B %d, %Y')`"
output: 
  pdf_document:
    highlight: "kate"
    df_print: "kable"
---

 <!-- Standard custom LaTeX commands -->
\newcommand{\abcd}{\begin{bmatrix}a&b\\
c&d\end{bmatrix}}
\newcommand{\m}[1]{\begin{bmatrix}#1\end{bmatrix}}

\newcommand{\vect}[1]{\begin{pmatrix}#1\end{pmatrix}}

\newcommand{\meq}[1]{\begin{split}#1\end{split}}

\newcommand{\bym}[1]{#1\times{m}}

\newcommand{\nby}[1]{n\times{#1}}

\newcommand{\subsp}[2]{\Bigg\{\begin{bmatrix}#1\end{bmatrix}:#2\Bigg\}}

\newcommand{\proj}[2]{\text{proj}_#1(#2)}

\newcommand{\refl}[2]{\text{refl}_#1(#2)}

\newcommand{\sumn}{\sum_{i=1}^n}

<!-- % 1: term 1 -->
<!-- % 2: subscript 1 -->
<!-- % 3: term 2 -->
<!-- % 4: subscript 2 -->
<!-- % 5. operation -->
\newcommand{\dotsn}[5]{#1_{1}#3_{1}#5{#1}_{2}#3_{2}{#5}\dots{#5}#1_{#2}#3_{#4}}

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = "", fig.pos = "", warning = FALSE,
                      tidy = TRUE, fig.align = "center", results = "asis", highlight = TRUE)

library(tidyverse)
library(rlang)
library(matador)
```

## 1.

Just find the eigens:

\[A = \begin{bmatrix}
  1 & -1\\
  2 & 4\\
\end{bmatrix}\]

\[
  \begin{vmatrix}
    1 - \lambda & 2\\
    2 & 4 - \lambda\\
  \end{vmatrix}x = 0
\]

$$
  \begin{aligned}
    & \lambda^2 -5\lambda +6 = 0\\
    & (\lambda -3)(\lambda -2) = 0\\
    & \lambda_1 = 2 \quad \lambda_2 = 3
  \end{aligned}
$$

\[x_1 = \begin{bmatrix}
  1 & -1\\
  2 & 4\\
\end{bmatrix} - \begin{bmatrix}
  2 & 0\\
  0 & 2\\
\end{bmatrix}  = \begin{bmatrix}
  -1 & -1\\
  2  & 2\\
\end{bmatrix} = \begin{bmatrix}
  -1\\
  1\\
\end{bmatrix}\]

The second eigenvector is\[\begin{bmatrix}
  -1/2\\
  1\\
\end{bmatrix}\]

Sure enough, $3+2 =1 +4=5$ and $3(2) =4(1) - (-1)(2)=6$.

## 3.

The values are shifted down 7, so $\lambda_1 = -5$ and $\lambda_2= -4$. But the vectors remain the same.

## 5.

\[A = \begin{bmatrix}
  3 & 4 & 2\\
  0 & 1 & 2\\
  0 & 0 & 0\\
\end{bmatrix}\]
\[(3-\lambda)(1 -\lambda)(0) = 0\]
\[\lambda_1 = 3\quad\lambda_2 =1\quad\lambda_3 = 0 \]

\[
     \begin{bmatrix}
      0 & 4 & 2\\
      0 & -2 & 2\\
      0 & 0 & -3
    \end{bmatrix}\implies x_1 = \begin{bmatrix}
      1\\
      0\\
      0\\
    \end{bmatrix}
\]

\[A - \lambda_2I = \begin{bmatrix}
  2 & 4 & 2\\
  0 & 0 & 2\\
  0 & 0 & -1\\
\end{bmatrix} \implies x_2 = \begin{bmatrix}
  -2\\
  1\\
  0\\
\end{bmatrix}\]

And for the last eigenvalue 0, just the kernel of $A$ itself, \[\begin{bmatrix}
  2\\
  0\\
  1\\
\end{bmatrix}
\]
For $B$, the determinant is -8, since it takes a row swap to diagonalize :

The eigenvalues must sum to 2 (the trace) and have a product of -8, which implies they are $\lambda = (2, 2, -2)$. So the vectors are 

$$
  \begin{aligned}
    & \begin{bmatrix}
      -2 & 0 & 2\\
      0 & 0 & 0\\
      2 & 0 & -2\\
    \end{bmatrix} \implies x_1 = \begin{bmatrix}
      1\\
      0\\
      1\\
    \end{bmatrix}
  \end{aligned}
$$

and 

$$
  \begin{aligned}
    & \begin{bmatrix}
      2 & 0 & 2\\
      0 & 4 & 0\\
      2 & 0 & 2\\
    \end{bmatrix} \implies x_2 = \begin{bmatrix}
      -1\\
      0\\
      1\\
    \end{bmatrix}
  \end{aligned}
$$


## 6.

If we consider $A = \m{1 & 2\\4 & 6}$ and $B = \m{1 & 2\\3 &4}$, the characteristic polynomials $\lambda^2 -7\lambda -2$ and $\lambda^2 - 5\lambda -2$ are clearly different. We have subtracted 2 from the trace, hence the difference.
Zero eigenvalues are not changed by elimination because they represent a vector that _already_ solves $Ax=0x=0$. Because row operations do not distrurb the kernel, since they respect row space, zero eigenvalues remain unchanged.

## 7.

a. If $B = A - 7I$, algebra shows that:

$$
  \begin{aligned}
    & Ax = \lambda x\\
    & (A-7I)x = \lambda x\\
    & Ax -7x = \lambda x\\
    & Ax = \lambda x + 7x \\
    & Ax = (\lambda + 7)x
  \end{aligned}
$$

So the eigenvalue for $A$ is 7 less than for $B$.

b. $\det(A^{-1}) = 1/ \det(A)$

$$
  \begin{aligned}
    & Ax = \lambda x\\
    & (A^{-1})^2Ax=(A^{-1})^2 \lambda x\\
    & A^{-1}x = A^{-1}x
  \end{aligned}
$$

## 8.

If we set $\lambda$ to 0...
$$
  \begin{aligned}
    & \det(A - \lambda I) = (\lambda_1 - \lambda)(\lambda_2 - \lambda) \dots (\lambda_n - \lambda)\\
    & \det(A) = \prod_{i=1}^n\lambda_i
  \end{aligned}
$$

## 9.

$$
  \begin{aligned}
    & (-1)^n\lambda^n +(-1)^{n-1}(trA)\lambda^{n-1}+\dots + \det A=0\\
    &-\lambda^n +(trA)(-\lambda)^{n-1} + \text{some convoluted polynomial} = 0\\
    & -\lambda^{n-1}(-\lambda + tr(A)) + \dots =0
  \end{aligned}
$$

## 10.

\[A=  \begin{bmatrix}
  2 & 0\\
  0 & 3
\end{bmatrix} \quad B = \begin{bmatrix}
  1 & 1\\
  1 & 1
\end{bmatrix}\]

\[\lambda_A = 2,3 \quad \lambda_b = 0, 2 \quad \lambda_{A+B} = \frac{7 \pm \sqrt{3}}{2}, \quad \lambda_{AB} = 0, 5\]

As we'd expect, $2 + 3 + 0 + 2=7$ and \[
2 \cdot 3 \cdot 0 \cdot 2 = 0 \cdot 5\], since

\[(A + B)x = \lambda x \implies Ax + Bx = \lambda x\]

## 11.
The eigen _values_ of $A$ and $A^T$ are the same because $\det(A^T) = \det(A)$, and the trace remains constant as well. But the vectors are different. Consider $\m{1 &2\\0 & 0}$ and $\m{1& 0\\ 2& 0}$. The eigenvalues are both 1 and 0, but the vectors are very different: $(\m{1\\0}, \m{-2\\1})$ for the first, $(\m{0\\1}, \m{1/2\\1})$ for the second. 

## 12.

If $A = \m{0 & 1\\ 1 & 0}$ and $B = \m{2 & 0\\0 &2}$, then for $A$ the eigens are $\pm1$, for $B$ both are 2. But for $A + B = \m{2 & 1\\ 1 & 2}$, the eigenvalues are 3 and 1. But $3 +1 = -1 + 1 + 2 + 2 = 4$, while 

## 12.

a. 

$$
  \begin{aligned}
    & A = \begin{bmatrix}
      3 & 4\\
      4 & -3\\
    \end{bmatrix}\\
    & (3 - \lambda)(-3 - \lambda) -4(4) = 0\\
    & \lambda^2 - 15 = 0\\
    & \lambda_1 = 5, \lambda_2 = -5
  \end{aligned}
$$

For the vectors:

$$
  \begin{aligned}
    & A - \lambda_1I = \begin{bmatrix}
      -2 & 4\\
      4 & -8\\
    \end{bmatrix} \implies x_1 = \begin{bmatrix}
      2\\
      1\\
    \end{bmatrix}
  \end{aligned}
$$

$$
  \begin{aligned}
    & A - \lambda_2I = \begin{bmatrix}
      8 & 4\\
      4 & 2\\
    \end{bmatrix} \implies x_2 = \begin{bmatrix}
      -1/2\\
      1\\
    \end{bmatrix}
  \end{aligned}
$$

For the general $\m{1 & b\\ b & 1}$ case, the polynomial works out:

$$
  \begin{aligned}
    & (a-\lambda)(a-\lambda) - b^2 = 0\\
    & \lambda^2 -2a \lambda - b^2 = 0
  \end{aligned}
$$

We resort to the quadratic formula and get a nice simplification:

$$
  \begin{aligned}
    & \lambda = \frac{2a \pm \sqrt{(2a)^2 - 4(a^2 - b^2)}}{2}\\
    & =\frac{2a \pm \sqrt{4b^2}}{2}\\
    & = \frac{2a \pm 2b}{2}\\
    & = a \pm b
  \end{aligned}
$$

## 13.

Given this, $tr(A) = 1 +2 +3 + 7 + 8 +9= 30$

## 14.

Given this matrix:

```{r, results = 'asis'}
mat2latex(matrix(rep(1, 16), nrow = 4))
```

rank is clearly 1. Three eigenvalues are 0, and the remaining one is 4, because $\sum \lambda = \text{trace}(A)$

For the matrix
\[
\begin{bmatrix}
  0 & 1 & 0 & 1\\
  1 & 0 & 1 & 0\\
  0 & 1 & 0 & 1\\
  1 & 0 & 1 & 0\\
\end{bmatrix}
\]
rank is 2, meaning two eigenvalues are 0. The other two are $\pm 2$.

## 15.

For the first matrix in the previous problem, if it is $n \times n$, then $n-1$ eigenvalues are 0 and the reamining one is $n$. In the second matrix, all but 2 eigenvalues are 0, and the remaining 2 are $\pm n -2$

## 16.

If the matrix is:

```{r, results='asis'}
mat2latex(square(rep(1, 16)) - diag(nrow = 4))
```

All the eigenvalues are shifted down 1, so three are now -1 and the remaining one is 3 (in order to sum to a trace of 0).

## 18.

$A$ has eigenvalues $(0, 3, 5)$ with eigenvectors $u, v, w$.

a. Then $u$ is a basis for the kernel because $Au = 0u$ by definition. The other two eigenvectors provide a basis for the image.

c. $Ax =u$ has no solution because $Au = \lambda u = 0u = u$. All multiples of $u$ are in the kernel.

## 19.

The eigenvalues of $A$ are $(1, 1/2)$ and of $A^2$ $(1, 1/4)$. Since $A^n =  S \Lambda^n S^{-1}$ and $(1/2)^2 = 1/2(1/2) = 1/4$, halving $A + A^{\infty}$ completes one-haldf of the exponential decay the eigenvalue $1/2$ has to undergo before reaching 0 at the steady state.

## 20.

$A +I$ has the same eigenvectors as $A$, but its eigenvalues are increased by 1. 

The eigenvalues are

$$
  \begin{aligned}
    & (1- \lambda)(3 - \lambda) - 2(4) = 0\\
    & \lambda^2 - 4 \lambda - 8 =0\\
    & \frac{4 \pm \sqrt{16 - 4(1)(-8)}}{2(-4)}\\
    & \frac{4 \pm 4 \sqrt{3}}{2}\\
    & 2 \pm 2 \sqrt{3}
  \end{aligned}
$$

Not going to bother working out the vectors.

## 21.

The eigenvalues of $A^{-1}$ are the inverse of those of $A$, and its eigenbasis is the inverse of $A$'s eigenbasis.

## 22.

$A^2$ has the same eigenvectors as $A$, but its eigenvalues are squared ($\lambda^2 = 9, 4$).

$$
  \begin{aligned}
    & A = \begin{bmatrix}
      -1 & 3\\
      2 & 0\\
    \end{bmatrix}\\
    & \lambda^2 + \lambda - 6 = 0\\
    & \lambda = -3, 2\\
    & S = \begin{bmatrix}
      -3/2 & 1\\
      1& 1\\
    \end{bmatrix}
  \end{aligned}
$$
## 23.

If you know an eigenvector, find $\lambda$ by multiplying it by $A$ and finding the scaling
factor.

If you know an eigenvalue, find the eigenvector by subtracting $\lambda I$ from $A$ and finding a basis for the kernel.

## 24.

Some proofs.

a.

$$
  \begin{aligned}
    & Ax = \lambda x\\
    & A^2x = A \lambda x\\
    & A^2 x = \lambda Ax\\
    & A^2x = \lambda^2 x
  \end{aligned}
$$

b. 
$$
  \begin{aligned}
    & Ax = \lambda x\\
    & (A^{-1})^2Ax =(A^{-1})^2 \lambda x\\
    & A^{-1} x = (A^{-1})^2\lambda x\\
    & A^{-1} x = \lambda  (\lambda^{-1})^2 x\\
    & = \lambda ^{-1}x
  \end{aligned}
$$
c. 
$$
  \begin{aligned}
    & Ax + x = \lambda x +x \\
    & (A +I)x = \lambda_x + x\\
    &= (\lambda +1)x
  \end{aligned}
$$

## 25.

```{r, results = "asis"}
u <-  c(1, 1, 3, 5) /6

P <- tcrossprod(u)
mat2latex(round(P %*% u, digits = 3))
```

Since $P$ only has rank 1, and is symmetric, an orthogonal vector with $\lambda = 0$ would be $\m{-1 1\\0\\0}$.

The three eigenvectors with $\lambda = 0$ are the bases of $A^{\perp}$, which is also the kernel since $A$ is symmetric. $A^T$ reduces to one row $\m{1 & 1 & 3 &5}$, which implies a kernel basis of 

\[ \begin{bmatrix}
  -1 & 3 & 5\\
  1 & 0 & 0\\
  0 & 1 & 0\\
  0 & 0 & 1\\
\end{bmatrix}\]


## 26.

Given the rotation matrix

\[Q = \begin{bmatrix}
  \cos \theta & -\sin \theta\\
  \sin \theta & cos \theta\\
\end{bmatrix}\]

The determinant works out to

$$
  \begin{aligned}
    & \det(Q - \lambda I) = (\cos - \lambda)^2 -(\sin)(-\sin)\\
    & = \cos^2 + \lambda^2 - 2 \lambda \cos - \sin^2
  \end{aligned}
$$

## 27.

Every permutation matrix has an eigenvalue of 1 (for a vector fo ones). We can find others.

For

\[ \begin{bmatrix}
  0 & 1 & 0\\
  0 & 0 & 1\\
  1 & 0 & 0\\
\end{bmatrix}\]
determinant is 1 (two row swaps from the identity, and trace 0, so $1 + \lambda_2 + \lambda_3 =0$ and $1\times \lambda_2 \lambda_3=1$). Since trace is 0, the characterictic polynomial reduces to $- \lambda^3 + 0 + 1/2(0) + 1=0$. SO $\lambda^3 = 1$. FO the others:

\[
  \begin{aligned}
    & \lambda(\lambda^2 + \lambda +1) = 0)
  \end{aligned}
\]
By the quadratic formula:

\[\lambda = \frac{-1 \pm i \sqrt3}{2}\]

So there are two complex roots. 
For 
\[ \begin{bmatrix}
  0 & 0 & 1\\
  0 & 1 & 0\\
  1 & 0 & 0\\
\end{bmatrix}\]
determinant is -1 (1 row swap) and trace is 1. This implies the remaining eigenvalues are $\pm 1$. 

# 28.

Technically correct, though lazy.
$$
 \begin{bmatrix}
  4 & 0\\
  0 & 5
\end{bmatrix} \quad
\begin{bmatrix}
  5 & -1000000\\
  0 & 4
\end{bmatrix}
\quad
\begin{bmatrix}
  5 & 0\\
  3 & 4
\end{bmatrix}
$$

## 29.

We know the rank of $B$ (2), the determinant of $B^TB$ ($\det(B)^2 = 0^2 =0)$, and the eigenvalues of $B + I)^{-1}$ (1, 1/2, and 1/3). We don't know the eigenvalues of $B^TB$.

## 30.


Given \[\begin{bmatrix}
  0 & 1\\
  c & d\\
\end{bmatrix}\]

$c = 4+7 = 11$ and $0(1) -d=28$ so $d =-28$.

## 31. 

$c=0$ so the trace sums to 0. $a = 0$ and $b=9$ so the determinant remains 0 no matter which eigenvalue is subtracted; those choices make row 3 a multiple of 2 if a nonzero. eigenvalue is subtracted and of row 1 and 2 if the eigenvalue is 0.

## 32.

$\lambda = (0, 1, -1/2)$ because all Markovs have 1 as an eigenvalue, singularity means 0 is an eigenvalue, and the eigenvalues must sum to the trace.
## 33.

Three such matrices are:
$$
 \begin{bmatrix}
  0 & 0\\
  0 & 0\\
\end{bmatrix},
 \begin{bmatrix}
   -1 & -1\\
    1 & 1\\
 \end{bmatrix},
 \begin{bmatrix}
   2 & -2\\
   2 & -2\\
 \end{bmatrix}
$$
## 34.

Given rank 1, two eigenvalues are 0, leaving one as six. 

The eigenvectors:

\[A = \begin{bmatrix}
  1 & -1 & 0\\
  2 & 1 & -2\\
  1 & 1/2 & 1
\end{bmatrix}\]

## 35.

$Ax = Bx = \lambda x$
## 36.

a. $\lambda = (1, 4, 6)$

b. $\lambda = (2, \pm \sqrt 6)$

c. $\lambda = (0, 0, 6)$

## 37.

Given $a+b =c +d$, $A\m{1\\1} = \m{1 +b\\c+d}$, which means $\lambda x$ has equal values and is therefore a scalar multiple of $x$. Then the eigenvalues are $a+b$ and $c +d$, which must be equal. 

## 39.

Yes. This is easy to show geometrically, the matrix of a 120-degree rotation cubed gives the identity.

```{r, results = "asis"}
theta <- (4 * pi)/3

mat2latex(round(matador::square(cos(theta), sin(theta), -sin(theta), cos(theta)) %^% 3))
```

## 40.

For permutation matrices in general, determinants are $\pm 1$ (depending on the number of swaps), the trace varies from 0 to 3, and the possible eigenvalues are $\pm1$ and nasty complex roots of the characteristic polynomial. Pivots are always 1 or 0.
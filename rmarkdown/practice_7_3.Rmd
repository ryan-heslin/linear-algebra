---
title: "Section 7.3 Problems"
author: "Ryan Heslin"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
output: 
  pdf_document:
    highlight: "kate"
    df_print: "kable"
---

 <!-- Standard custom LaTeX commands -->
\newcommand{\abcd}{\begin{bmatrix}a&b\\
c&d\end{bmatrix}}
\newcommand{\m}[1]{\begin{bmatrix}#1\end{bmatrix}}

\newcommand{\vect}[1]{\begin{pmatrix}#1\end{pmatrix}}

\newcommand{\meq}[1]{\begin{split}#1\end{split}}

\newcommand{\bym}[1]{#1\times{m}}

\newcommand{\nby}[1]{n\times{#1}}

\newcommand{\subsp}[2]{\Bigg\{\begin{bmatrix}#1\end{bmatrix}:#2\Bigg\}}

\newcommand{\proj}[2]{\text{proj}_#1(#2)}

\newcommand{\refl}[2]{\text{refl}_#1(#2)}

\newcommand{\sumn}{\sum_{i=1}^n}

<!-- % 1: term 1 -->
<!-- % 2: subscript 1 -->
<!-- % 3: term 2 -->
<!-- % 4: subscript 2 -->
<!-- % 5. operation -->
\newcommand{\dotsn}[5]{#1_{1}#3_{1}#5{#1}_{2}#3_{2}{#5}\dots{#5}#1_{#2}#3_{#4}}

```{r setup, include=FALSE}

knitr::opts_chunk$set(
  echo = TRUE,
  comment = "",
  fig.pos = "",
  warning = FALSE,
  tidy = TRUE,
  fig.align = "center",
  highlight = TRUE
)

library(tidyverse)
library(rlang)
```

##1. 

Just find some eigenvectors.

\[
  \begin{aligned}
    & A = \begin{bmatrix}
      6 & 3\\
      2 & 7
    \end{bmatrix}\\
    & \lambda = (9, 4)\\
  & S = \begin{bmatrix}
    3 & -2\\
    1 & 1
  \end{bmatrix}
  \end{aligned}
\]

## 5.

None real, but $\lambda = 1 \pm i$

## 10.

\[
  \begin{aligned}
    & A = \begin{bmatrix}
      1 & -1 & 0\\
      0 & 0 & 0\\
      0 & 0 & 1
    \end{bmatrix}
    \begin{bmatrix}
      1 & 0 & 0\\
      0 & 0 & 0\\
      0 & 0 & 1
    \end{bmatrix}
    \begin{bmatrix}
      1 & -1 & 0\\
      0 & 0 & 0\\
      0 & 0 & 1
    \end{bmatrix}^{-1}
  \end{aligned}
\]

## 17.

$\lambda = (0, 0, 1, 1)$. Diagonalizable.

## 18. 

Not diagonalizable; the only two eigenspace vectors are $\begin{bmatrix}0\\1\\0\\0\end{bmatrix}$ 
and $\begin{bmatrix}0\\1\\0\\1\end{bmatrix}$



## 21.

```{r, results = "asis"}
S <- matrix(c(1, 2, 2, 3), nrow = 2)
Lambda <- diag(x = c(1, 2), nrow = 2)
A <- S %*% Lambda %*% solve(S)
A
```

## 22.

Just $\m{7 & 0\\ 0 & 7}$

## 23.

For $\m{1 & 1\\0 &1}$, $\lambda =1$, but since that yields $\m{0&1 \\0 &1}$, the only eigenvector is $e_1$. That makes sense, since $Ae_1$ just selects the first column, which contains only  single scalar.

## 25.

If $c$ only is 0, then  $A$ has distinct eigenvectors. If all three are 0, then $A$ has just one eigenvector for the repeat eigenvalue 0. 

## 26. 

Since $\det A = \prod^n_{i=1} \lambda_i$, if the determinant is negative but $n$ is positive, there must be an odd number of negative eigenvalues.

## 27.

$\lambda = (1, 5)$.

## 28. 

The eigenvalues are all just $k$, multiplicity $n$.
They share an eigenspace of every standard vector but the last.

## 29. 
Algebraic and geometric multiplicity are both $n-r$, since by rank-nullity $\ker(A)$ has dimension $n-r$.

## 30. 

Algebraic multiplicity is $n-m$

## 31. 
If an eigenbasis exist, both multiplicities sum to $n$, though geometric and algebraic multiplicity need not match for every distinct eigenvalue.

## 32.

The algebraic multiplicities are the same, since the eigenvalues are shared. The dimension of $\ker(A - I \lambda)$ is $n - rank(A^T - \lambda I)$. So the dimension of the transpose's eigenspace is the orthogonal complement of $A$'s image, and vice versa. So if $n =3$, then a two-dimensional eigenspace in $A$ corresponds to a one-dimensional eigenspace in $A^T$ and vice versa. 

#33.

\[
  \begin{aligned}
    & (B - \Lambda) = S^{-1}(A - \Lambda)S\\
    & = S^{-1}(AS -  \Lambda S)\\
    & = S^{-1}AS - S^{-1} \Lambda S\\
    & = B - \Lambda
  \end{aligned}
\]

## 34.

\[
  \begin{aligned}
    & B = S^{-1}AS\\
    & SB = AS\\
    &S(Bx) = A(Sx)
  \end{aligned}
\]
So if $Bx=0$, $Sx = 0$ as well.

b.

Invertible, so isomorphic.
\[
  \begin{aligned}
    & T(X) = Sx\\
    & T^{-1}x = S^{-1}Sx = x
  \end{aligned}
\]

c. 
Since $S$ has full rank, $Sx$ has the rank of $\ker B$, since $x$ is some linear combination of the kernel, so the dimension remains the same. Since $A$ and $B$ both have $n$ columns, if the kernels have dimension $m$ since hey both have dimension $n-m$.

## 35.

No, the traces are different.

## 36. 

No, for the same reasoning. 

## 37.

a. 
\[
  \begin{aligned}
    & Av \cdot w = v \cdot Aw\\
    & v^T A^Tw = v^TAw\\
    & v^T Aw = v^TAw
  \end{aligned}
\]

The proof of symmetric orthogonal eigenvectors

b.
\[
  \begin{aligned}
    & Av \cdot w = v \cdot Aw\\
    & \lambda_v v^Tw = \lambda_w v^Tw
  \end{aligned}
\]

Since $\lambda_w \neq \lambda_v$, this holds only if $v \cdot w =0$.

## 38.

Since a rotation matrix rotates all vectors by $\theta$, no real vector satisfies this criterion. But eigenvectors still exist because the characteristic polynomial must have roots, 
but they lie on $C^3$ and are complex.
If the matrix is $\pm I_3$, the eigenvalues and 
eigenvectors are of course real.

## 39.

a. $n-m$ are 0, with equal geometric multiplicity because $\dim (\ker(A)) = n - m$ The remaining $m$ are distinct and have orthogonal eigenvectors because all projection matrices are symmetric.

b. Reflection matrices only have eigenvalues $\pm 1$ (this makes obvious geometric sense),
so algebraic multiplicity is greater than 1. The eigenvectors are bases of the subspaces of reflection, since these retain their position.

## 40.

$a=0$.

## 41.

All possible values.

## 42.

$b \neq 1$

## 43.

$a \neq 0$

## 44.

All values, since this is always symmetric.

## 45

Always diagonalizable.

## 46.

At least one of the constants is 0.

## 47.

$a=b=c=0$.

## 49. 

Actually diagonalizable, because I failed to take into account complex roots.

## 51. 

Simple enough. 

\[
    \begin{aligned}
    & \det A =  -\lambda(- \lambda(c - \lambda) - b(1)) + a(1(1) - \lambda (0))\\
    & = -\lambda(- \lambda c + \lambda^2 - b) + a(1) \\ 
    & = - \lambda^2 + \lambda^2 c - \lambda b + a
    \end{aligned}
\]

## 52. 

From that pattern:

\[
    \lambda^n - \lambda^{n -1}a_{n-1} + \lambda^{n-2}a_{n-2} + \dots a_0
\]
assuming $n$ is even; otherwise the first term is negative, the second positive, and so on.


## 55.

```{r}
set.seed(1)
A <- matrix(c(0, 1, 0, 0, 0, 1, -7, 1, 7), nrow = 3)
S <- matrix(c(1, 0, 5, 2, 1, 6, 3, 4, 0), nrow = 3)
B <- S %*% A %*% solve(S)
eigen(B)
```

## 56. 

Just find the characteristic polynomial, write 
the Frobenius companion matrix, and diagonalize with
a matrix copied from some website that has an integer inverse.

```{r}
set.seed(1)
A <- matrix(c(0, 1, 0, 0, 0, 1, 6, -11, 6), nrow = 3)
S <- matrix(c(1, 0, 5, 2, 1, 6, 3, 4, 0), nrow = 3)
B <- S %*% A %*% solve(S)
eigen(B)
```

---
title: "Notes"
author: "Ryan Heslin"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
output: 
  pdf_document:
    highlight: "kate"
    df_print: "kable"
---

 <!-- Standard custom LaTeX commands -->
\newcommand{\abcd}{\begin{bmatrix}a&b\\
c&d\end{bmatrix}}
\newcommand{\m}[1]{\begin{bmatrix}#1\end{bmatrix}}

\newcommand{\vect}[1]{\begin{pmatrix}#1\end{pmatrix}}

\newcommand{\meq}[1]{\begin{split}#1\end{split}}

\newcommand{\bym}[1]{#1\times{m}}

\newcommand{\nby}[1]{n\times{#1}}

\newcommand{\subsp}[2]{\Bigg\{\begin{bmatrix}#1\end{bmatrix}:#2\Bigg\}}

\newcommand{\proj}[2]{\text{proj}_#1(#2)}

\newcommand{\refl}[2]{\text{refl}_#1(#2)}

\newcommand{\sumn}{\sum_{i=1}^n}

<!-- % 1: term 1 -->
<!-- % 2: subscript 1 -->
<!-- % 3: term 2 -->
<!-- % 4: subscript 2 -->
<!-- % 5. operation -->
\newcommand{\dotsn}[5]{#1_{1}#3_{1}#5{#1}_{2}#3_{2}{#5}\dots{#5}#1_{#2}#3_{#4}}

\newcommand{\rot}[1]{
\begin{bmatrix}
\cos{(#1)} & -\sin{(#1)}\\

\sin{(#1)} & \cos{(#1)}\\
\end{bmatrix}
}
```{r setup, include=FALSE}

knitr::opts_chunk$set(
  echo = TRUE,
  comment = "",
  fig.pos = "",
  warning = FALSE,
  tidy = TRUE,
  fig.align = "center",
  highlight = TRUE
)

library(tidyverse)
library(rlang)
```
## 1.

If 0 is an eigenvalue, $\det A =0$ because the determinant is the product of an eigenvalue.

## 2.

True, that is the characteristic polynomial.

## 3.

True.

## 4.

True.

## 5.

False; a repeat eigenvalue may correspond to a single eigenvector.

## 6.

True, diagonalization requires an eigenbasis.

## 7.

True. The eigenvlues of a diaonal matrix are just the diagonal, so $\lambda_n x_n = \lambda_n e_n$

## 8.

True.

\[
  \begin{aligned}
    & Ax = \lambda x\\
    & A^3 x = A^2 \lambda x\\
    & = A^2Ax\\
    & = A^3x
  \end{aligned}
\]

## 9.

False; an odd-rank skew-symmetric has 0 as an eigenvalue, thought he others are complex

## 10.

True.

\[
  \begin{aligned}
    & A^2 = -I\\
    &
    Av^2 = -v\\\
    & \lambda^2v = -v
  \end{aligned}
\]
But odd-ranked matrices can't have purely imaginary eignvalues, so False.

## 11.

True, since eignvalues sum to the trace.

## 12.

True; that means multiplication always respects vector length.

## 13.

True. Rotation matrices are always skew-symmetric, so they have unitary complex eignvectors.

## 14.

True; that is simply the dimension of the kernel, since $A - 0I = A$.

## 15.

True. All similar matrices arediagonalizable,a dn teh

## 16.

## 17.

False.
\[A = \begin{bmatrix}
  1 & 1\\
  0 & 1
\end{bmatrix}\]

## 18.

## 19.

## 20.

## 21.

False. Consider

\[A = \begin{bmatrix}
  1 & 1\\
  1 & 1
\end{bmatrix}\]

## 22.

## 23.

## 24.

## 25.

## 26.

## 27.

## 28.

## 29.

## 30.

## 31.

True. Distinct eigenvalues always correspond to independent eigenvectors.

## 32.

## 33.
False. Orhtogonal matrices can be diagonalizable yet cannot ahve more than 2 distinct eigenvalues.

## 34.

## 35.

False. Consider
\[
\begin{bmatrix}
  0 & 1\\
  0 & 0
\end{bmatrix}
\]
and its transpose.
## 36.

## 37.
False.
\[
  \begin{aligned}
    & \lambda_v v = Av\\
    & \lambda_w w = Aw\\
    & A(v +w) = \lambda_v v + \lambda_w w
  \end{aligned}
\]

## 38.

## 39.

## 40.

## 41.

## 42.

## 43.

True, from the definition of similarity.

## 44.

## 45.

## 46.

## 47.

True by definition.

## 48.

True. The number of 0 eigenvalues is $n - \text{rank}$, so each distinct eigenvalue adds a dimension of rank.

## 49.

True. The image of $A$ is just a single vector if it has rank 1, so that vector satisfiies $Ax = \lambda x$.

## 50.

True. Then the one nonzero eigenvalue has geometric multiplicity 1 (corersponding to the image of $A$) and the $n - 1$ 0 eigenvalues have the geomtric multiplicity of the kernel's dimesnion, $n-1$

## 51.

## 52.

## 53.

True. If $\lambda x = Ax =0$, it is in the kernel; otherwise it is in the image, since any scalar of $v$ still qualifies as an eigenvector.

## 54.

True. Symmetric matrices guarantee orthogononal and thus distinct - eigenvectors.

## 55.

True. $Au = \lambda u = 4u$.

## 56.

True. This eigenvector corresponds to the subspace $u$ the matrix is projecting into, since $Pu = u$.

## 57.

## 58.


---
title: "Section 3.4 Problems"
author: "Ryan Heslin"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
output: 
  pdf_document:
    highlight: "kate"
    df_print: "kable"
---

 <!-- Standard custom LaTeX commands -->
\newcommand{\abcd}{\begin{bmatrix}a&b\\
c&d\end{bmatrix}}
\newcommand{\m}[1]{\begin{bmatrix}#1\end{bmatrix}}

\newcommand{\vect}[1]{\begin{pmatrix}#1\end{pmatrix}}

\newcommand{\meq}[1]{\begin{split}#1\end{split}}

\newcommand{\bym}[1]{#1\times{m}}

\newcommand{\nby}[1]{n\times{#1}}

\newcommand{\subsp}[2]{\Bigg\{\begin{bmatrix}#1\end{bmatrix}:#2\Bigg\}}

\newcommand{\proj}[2]{\text{proj}_#1(#2)}

\newcommand{\refl}[2]{\text{refl}_#1(#2)}

\newcommand{\sumn}{\sum_{i=1}^n}

<!-- % 1: term 1 -->
<!-- % 2: subscript 1 -->
<!-- % 3: term 2 -->
<!-- % 4: subscript 2 -->
<!-- % 5. operation -->
\newcommand{\dotsn}[5]{#1_{1}#3_{1}#5{#1}_{2}#3_{2}{#5}\dots{#5}#1_{#2}#3_{#4}}

\newcommand{\rot}[1]{
\begin{bmatrix}
\cos{(#1)} & -\sin{(#1)}\\

\sin{(#1)} & \cos{(#1)}\\
\end{bmatrix}
}
```{r setup, include=FALSE}

knitr::opts_chunk$set(
  echo = TRUE,
  comment = "",
  fig.pos = "",
  warning = FALSE,
  tidy = TRUE,
  fig.align = "center",
  highlight = TRUE
)

library(tidyverse)
library(rlang)
library(matador)
```

Coordinate transformations. I write a function to compute the 
pseudoinverse to save time.

## 6.

```{r}
A_plus <- function(A){
  SVD <- svd(A, nu = nrow(A), nv = ncol(A))
  S_plus <- diag(x = SVD$d, nrow= ncol(A), ncol = nrow(A) )
 
  SVD$v %*% S_plus %*% t(SVD$u)
}

A_plus(matrix(c(1, 1, 0, 2, 0 ,1), nrow = 3)) %*% 2:4
```

## 10.

```{r, results = "asis"}
mat2latex(A_plus(matrix(c(8, 4, -1, 5, 2, -1), nrow = 3)) %*% c(1, -2, -2))
```

## 17.

\[[x]_B = \begin{bmatrix}
  1\\
  1\\
  -1
\end{bmatrix}
\]

## 19.

\[
  \begin{aligned}
    & A = \begin{bmatrix}
      0 & 1\\
      1 & 1
    \end{bmatrix}V = \begin{bmatrix}
      1 & 1\\
      1 & -1
    \end{bmatrix}\\
    & B = S^{-1}AS = \begin{bmatrix}
      2 & 0\\
      0 & 0
    \end{bmatrix}
  \end{aligned}
\]

## 23.

\[
  \begin{aligned}
    & A = \begin{bmatrix}
      5 & -3\\
      6 & -4
    \end{bmatrix}\quad & V = \begin{bmatrix}
      1 & 1\\
      1 & -1
    \end{bmatrix}\\
    & B = \begin{bmatrix}
      -4 & 0\\
      0 & -1
    \end{bmatrix}
  \end{aligned}
\]

## 24.

```{r, results = "asis"}
A <-square(13, 6, -20, -9)
S <- square(2, 1, 5, 3)

solve(S) %*% A %*% S %>%
  `(` %>% 
  mat2latex()

```

## 30.

```{r, results = "asis"}
A <- matrix(c(-1, 0, 3, 1, -2, -9, 0, 2, 6), nrow = 3)
S <- matrix(c(rep(1, 3), 0, 1, 2, 1, 2, 4), nrow = 3)
mat2latex(solve(S) %*% A %*% S)
```

## 31.

\[
  \begin{aligned}
    & T(X) v_2 \times x\\
    & = c_1(v_2 \times v_1) + c_2 (v_2 \times v_2) + c_3(v_2 \times v_3)\\
    & = -c_1v_3 + c_3v_1
  \end{aligned}
\]

\[B = \begin{bmatrix}
  0 & 0 & 1\\
  0 & 0 & 0\\
  -1 & 0 & 0
\end{bmatrix}\]

## 33.

\[T(x) = (v2 \cdot x )v_2\]

\[B = \begin{bmatrix}
  0 & 0 & 0\\
  0 & 1 & 0\\
  0 & 0 & 0
\end{bmatrix} \]

## 37.

\[B = \begin{bmatrix}
  1 & 1\\
  2 & -2
\end{bmatrix}\]

## 38.

\[ \begin{bmatrix}
  2 & 2\\
  3 & -3
\end{bmatrix}\]

## 39.

\[ \begin{bmatrix}
  1 & -1 & 1\\
  2 & -1 & -2\\
  3 & -1 &1
\end{bmatrix} \]

## 40.

\[ \begin{bmatrix}
  1 & -1 & -1/2\\
  1 & 1 & -1/2\\
  1 & 0 & 1
\end{bmatrix}\]

## 43.

\[x = \begin{bmatrix}
  2\\
  -3\\
  2
\end{bmatrix}\]

## 46. 
I had to look up the solution: it's an ugly
system of equations for each element of the
two basis vectors.

```{r, results = "asis"}
A <- matrix(c(2, 0, 0, -1, 0, 0,
             0, 2, 0, 0, -1, 0,
             0, 0, 2, 0, 0, -1,
             1, 2, 1, 0, 0, 0,
             0, 0, 0, 1, 2, 1), nrow = 5,
            byrow = TRUE)
answer <- A_plus(A)  %*% c(1, -1, 1, 0, 0)
answer <- cbind(answer[1:3], answer[4:6])
answer <- answer / 5
mat2latex(answer)
```

## 47.

\[T = \begin{bmatrix}
  b & a\\
  d & c
\end{bmatrix}\]

## 50.

a. $\m{2\\-1}$ and $\m{1\\-2}$

b. It is at the center of the northeast
hexagon from the one with the labeled vectors.

c. Center.

## 51.
Let $S$ be the matrix of the basis of the coordinate system. As a
basis, rank is $m$, so a left inverse is guaranteed to exist:
\[
  \begin{aligned}
    & x = S|x|_B\\
    & [x]_b = S^+x
  \end{aligned}
\]
Because $S^+$ is a linear transformation, $S^+(x + y)= S^+(x) + S^+(y)$.

## 52. 
See above. Being matrices, both $S^+$ and $S^{-1}$ are linear transformations.

## 53.

\[
  \begin{aligned}
    & B = \begin{bmatrix}
      1 & 2\\
      3 & 4
    \end{bmatrix}\\
    & B \begin{bmatrix}
      7\\
      11
    \end{bmatrix} = \begin{bmatrix}
      40\\
      58
    \end{bmatrix}
  \end{aligned}
\]

## 54.

Yes. Let $B$ be the matrix of basis $B$ and $F$ the basis of $F$.

Then $[v_i]_F$ is column $I$ of $BF$ Because $B$ and $F$ have full rank, so does $BF$, so $BF$ is a valid basis for $R^n$.

## 55.

The matrix that transforms standard coordinates into $R$-coordinates is the inverse of $R$'s basis matrix, and the one that transforms $B$ coordinates into standard coordinates is that of $B$'s basis. Therefore:

\[
  \begin{aligned}
    & P = \frac{1}{2}\begin{bmatrix}
      -4 & 3\\
      2 & -1
    \end{bmatrix}
    \begin{bmatrix}
      1 & 1\\
      1 & 2
    \end{bmatrix}\\
    & = \frac{1}{2} \begin{bmatrix}
      1 & 2\\
      1 & 0
    \end{bmatrix}
  \end{aligned}
\]

## 56.

\[
  \begin{aligned}
    & S \begin{bmatrix}
      1 & 2\\
      3 & 4
    \end{bmatrix} = \begin{bmatrix}
      3 & 2\\
      5 & 3
    \end{bmatrix}\\
    & S = \frac{1}{2} \begin{bmatrix}
      3 & 1\\
      1 & 1
    \end{bmatrix}
  \end{aligned}
\]

## 57.

In $R^3$, a reflection matrix about a plane preserves the portion of a vector parallel to a plane and subtracts the perpendicular portion. So in $R^3$, $V{\parallel}$ has dimension 2 and $v^{\perp}$ has dimension 1. So the matrix must have eigenvalues $1, 1, -1$ to perform this operation, which matches
```{r, results="asis"}
mat2latex(diag(x = c(1, 1, -2)))
```

## 58.

a.

\[
  \begin{aligned}
    & C_1v +c_2Av = 0\\
    &c_1A^2v + c_2a^3v= 0\\
    & c_1A^2v = 0\\
    &c_1 = 0
  \end{aligned}
\]

\[
  \begin{aligned}
    & c_1A^2v + c_2Av +c_3v = 0\\
    &c_1A^4v + c_2A^3v + c_3A^2v =0\\
    & c_3A^2v = 0\\
    & c_3 = 0
  \end{aligned}
\]

b.

\[
  \begin{aligned}
    & T(x) = Ax\\
    & = A^3vx_1 +A62vx_2 + Avx_3
  \end{aligned}
\]

implying the matrix

\[Ax = \begin{bmatrix}
  0 & | & |\\
  0 & A^2v & Av\\
  0 & | & |
\end{bmatrix}\]

## 59.

Yes, diagonal matrices are similar to triangulars with the same diagonal - 
so long as they have distinct eigenvectors.

## 60.

No, the second matrix has complex eigenvalues, the first doesn't.

## 61.
```{r}
A <- square(-5, 4, -9, 7)
B <- square(1, 0, 1, 1)
S <- B %*% solve(A)
```


## 63.

Yes; all rotation-scaling matrices in $R^2$ have eigenvalues 
\[
\pm \frac {i}{p^2 + q^2}
\]

## 64.

Yes, they both have the same characteristic polynomial.

## 65.

Proof of reflexively and symmetry of similarity:

\[
  \begin{aligned}
    & S = I\\
    & A = S^{-1}AS=A\\
    & A = S^{-1}B S\\
    & SA = BS\\
    &B = SAS^{-1}
  \end{aligned}
\]

## 67.

\[
  \begin{aligned}
    & B = \frac{1}{c} \begin{bmatrix}
      c & -a\\
      0 & 1
    \end{bmatrix}  \begin{bmatrix}
      a & b\\
      c & d
    \end{bmatrix}
    \begin{bmatrix}
      1 & a\\
      0 & c
    \end{bmatrix}\\
    & = \begin{bmatrix}
      0 & bc-ad\\
      1 & a-d
    \end{bmatrix}
  \end{aligned}
\]

## 66.

Diagonalizing a reflection
\[\begin{aligned}
B = \frac{1}{2a} \begin{bmatrix}
  b    & 1-a\\
  a-1 & b
\end{bmatrix}
\begin{bmatrix}
  a & b\\
  b & -a
\end{bmatrix}
\begin{bmatrix}
  b & a-1\\
  1-a & b
\end{bmatrix}\\
& = \frac{1}{2a} \begin{bmatrix}
  2-2a & 0\\
  0 & 2a-2
\end{bmatrix} \\
& = \begin{bmatrix}
  1 - 1/a & 0\\
  0 & 1 - 1 /a
\end{bmatrix}
\end{aligned}\]
## 69.

In the unlikely event anyone's reading this, I want to praise the author for smuggling in a diagonalization problem 
a few chapters before eigenvectors appear. Sneaky.

\[
  \begin{aligned}
    & S = \begin{bmatrix}
      1/ \sqrt 5 & 2/ \sqrt 5\\
      2 / \sqrt 5 & 1/ \sqrt 5
    \end{bmatrix}\\
    & S^{-1} A S = \begin{bmatrix}
      2 & 0\\
      0 & -1
    \end{bmatrix}
  \end{aligned}
\]

## 70.

No. The first column of $B$ must be $\m{a\\0}$, where $a$ is any real number. Then column 1 of the output is $a$ times column 1 of the input, which is incompatible with the permutation transformation.

## 71.

a. If $x \in \ker B$ and $B = S^{-1}AS$, then $S^{-1}ASx = 0 \implies Sx \in \ker A$. $(\ker S^{-1} = 0)$.  

b.
Showing the nullities are identical. $A$ just has its transformed
by $S$ first:
\[
  \begin{aligned}
    & B = S^{-1}AS\\
    & = S^{-1}SBS^{-1}SSx\\
   & = BSx
  \end{aligned}
\]

## 72.

Since $A$ and $B$ must have the same dimensions, from this it follows that $\text{rank} A = \text{rank} B$.

## 73.

## 74.

a. 0.

$T$ represents a rotation $2\pi/3$ radians about $P_2$; hence, it has no 
effect on that vector. 
```{r, results = "asis"}
solve(square(1, -1, -1, -1, 1, -1, -1, -1, 1)) %*% rep(1, 3)

A <- square(-1, -1, 1, 1, -1, -1, rep(1, 3)) %*% solve(square(rep(1, 3), -1, -1, 1, 1, -1, -1))

mat2latex(A %*% c(-1, 1, -1))
```

```{r, results="asis"}
S <- square(1, -1, -1, -1, 1, -1, -1, -1, 1)
B <-  solve(S) %*% A %*% S
mat2latex(B)
```

## 75.

\[B =  \begin{bmatrix}
  0 & -1\\
  1 & 0
\end{bmatrix}\]
The rotation does the same thing to
any orthogonal basis, being an orthogonal transformation,
so the matrix is the same.

## 76.

Here $S^{-1}= A$, so just the original
rotation matrix.

## 77.
Column $j$ of $B$ is column $n-j+1$ of $A$.

## 78.

```{r}
S <- diag(x = c(2, 5,10))
A <- square(.3, .1, .2, .2, .3, .2, .1,
            .3, .1)
B <- solve(S) %*% A %*% S
```

Here, $B = S^{-1}AS$ first finds the total cost of the produced amounts of good $j$ by industry $i$, then $S^{-1}$ divides again by price to express the interindustry demands in terms of goods alone.

## 81.

Arrant cheating, but it works.
```{r, results = "asis"}
A <- square(0, 0, 0, 1, 0, 1, 0, 1, 1)
eigen(A)$vectors %>% 
  apply(MARGIN = 2, function(x) x / x[1]) %>% 
  mat2latex
```